{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tQRbwtJAi58",
        "outputId": "841fbc0d-3736-44ae-8735-39cfd2fc5718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "            17, 18, 19, 20, 21, 22],\n",
            "           dtype='int64')\n",
            "   0_p  1_c  1_f  1_k  1_s  1_x  2_g  2_s  2_y  3_c  ...  21_n  21_s  21_v  \\\n",
            "0    1    0    0    0    0    1    0    1    0    0  ...     0     1     0   \n",
            "1    0    0    0    0    0    1    0    1    0    0  ...     1     0     0   \n",
            "2    0    0    0    0    0    0    0    1    0    0  ...     1     0     0   \n",
            "3    1    0    0    0    0    1    0    0    1    0  ...     0     1     0   \n",
            "4    0    0    0    0    0    1    0    1    0    0  ...     0     0     0   \n",
            "\n",
            "   21_y  22_g  22_l  22_m  22_p  22_u  22_w  \n",
            "0     0     0     0     0     0     1     0  \n",
            "1     0     1     0     0     0     0     0  \n",
            "2     0     0     0     1     0     0     0  \n",
            "3     0     0     0     0     0     1     0  \n",
            "4     0     1     0     0     0     0     0  \n",
            "\n",
            "[5 rows x 96 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statistics\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "caminho_arquivo = '/content/drive/My Drive/agaricus-lepiota.data'\n",
        "\n",
        "df = pd.read_csv(caminho_arquivo, header=None)\n",
        "# one-hot encoding! Dummizar.\n",
        "df_dummizado = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "print(df.columns)\n",
        "print(df_dummizado.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def impureza_gini_folha(alvo):\n",
        "  '''calculo de impureza de uma folha'''\n",
        "\n",
        "  if (len(alvo) == 0):\n",
        "    return 1\n",
        "\n",
        "  return 1 - (alvo.count(0)/len(alvo))**2 - (alvo.count(1)/len(alvo))**2\n",
        "\n",
        "print(impureza_gini_folha(df_dummizado[\"0_p\"].to_list()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fexBIBXMHP8d",
        "outputId": "8d7dbf2f-1fe1-4069-dc14-f459aafe7aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49935405449893955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def impureza_gini_coluna(df, coluna):\n",
        "    '''Calcula a impureza Gini para uma divisão baseada em uma coluna específica.'''\n",
        "    gini_true = impureza_gini_folha(df[df[coluna] == 1]['0_p'].to_list())\n",
        "    gini_false = impureza_gini_folha(df[df[coluna] == 0]['0_p'].to_list())\n",
        "\n",
        "    media_ponderada = (gini_true * df[df[coluna] == 1].shape[0] +\n",
        "                       gini_false * df[df[coluna] == 0].shape[0]) / df.shape[0]\n",
        "\n",
        "    return media_ponderada\n"
      ],
      "metadata": {
        "id": "5ykAUpfGIwjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def melhor_caracteristica_para_divisao(df):\n",
        "    menor_impureza = float('inf')\n",
        "    melhor_caracteristica = None\n",
        "\n",
        "    for coluna in df.columns:\n",
        "        if coluna == '0_p':  # Ignora a coluna target\n",
        "            continue\n",
        "\n",
        "        # Impureza para a divisão baseada na presença da característica\n",
        "        df_left = df[df[coluna] == 0]  # Característica ausente\n",
        "        df_right = df[df[coluna] == 1]  # Característica presente\n",
        "\n",
        "        impureza_left = impureza_gini_folha(df_left['0_p'].to_list())\n",
        "        impureza_right = impureza_gini_folha(df_right['0_p'].to_list())\n",
        "\n",
        "        # Calcula a impureza total ponderada para a divisão\n",
        "        n = len(df)\n",
        "        impureza_total = (len(df_left) / n) * impureza_left + (len(df_right) / n) * impureza_right\n",
        "\n",
        "        # Atualizando a melhor característica se a impureza total atual for menor\n",
        "        if impureza_total < menor_impureza:\n",
        "            menor_impureza = impureza_total\n",
        "            melhor_caracteristica = coluna\n",
        "\n",
        "    return melhor_caracteristica\n"
      ],
      "metadata": {
        "id": "zjG_OWFMVGJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir o dataset em conjuntos de treino e teste\n",
        "X = df_dummizado.drop(alvo, axis=1)\n",
        "y = df_dummizado[alvo]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Treinar a Random Forest\n",
        "forest = random_forest(train_df, n_trees=10, max_depth=10)\n",
        "\n",
        "# Testar o Modelo\n",
        "predictions = predict_forest(forest, test_df.drop(alvo, axis=1))"
      ],
      "metadata": {
        "id": "BObLZnYkD8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alvo = '0_p'\n",
        "\n",
        "def bootstrap_sample(df):\n",
        "    n_samples = df.shape[0]\n",
        "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "    return df.iloc[indices]\n",
        "\n",
        "def build_tree(df, depth=0, max_depth=10):\n",
        "  '''Arvore de decisão adaptada para Random Forest'''\n",
        "    # Verificar condição de parada\n",
        "  if len(df[alvo].unique()) == 1 or depth == max_depth:\n",
        "        return df[alvo].mode()[0]\n",
        "\n",
        "  melhor_caracteristica = melhor_caracteristica_para_divisao(df)\n",
        "  left_df = df[df[melhor_caracteristica] == 0]\n",
        "  right_df = df[df[melhor_caracteristica] == 1]\n",
        "  # Recursivamente construir subárvores\n",
        "  left_tree = build_tree(left_df, depth + 1, max_depth)\n",
        "  right_tree = build_tree(right_df, depth + 1, max_depth)\n",
        "  return {'caracteristica': melhor_caracteristica, 'left': left_tree, 'right': right_tree}\n"
      ],
      "metadata": {
        "id": "Iaxfn7lgc372"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tree(tree, row):\n",
        "  '''Prever com uma árvore'''\n",
        "  if not isinstance(tree, dict):  # Verifica se é um nó folha\n",
        "      return tree\n",
        "  if row[tree['caracteristica']] == 0:\n",
        "      return predict_tree(tree['left'], row)\n",
        "  else:\n",
        "      return predict_tree(tree['right'], row)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pzp7Zerp4qai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest(df, n_trees=10, max_depth=10):\n",
        "    trees = []\n",
        "    for _ in range(n_trees):\n",
        "        df_sample = bootstrap_sample(df)\n",
        "        tree = build_tree(df_sample, max_depth=max_depth)\n",
        "        trees.append(tree)\n",
        "    return trees\n",
        "\n",
        "def predict_forest(forest, X_test):\n",
        "  '''Prever com a Random Forest'''\n",
        "\n",
        "  # Inicializar uma lista para armazenar as predições finais para cada observação\n",
        "  final_predictions = []\n",
        "  # Iterar sobre cada observação no conjunto de teste\n",
        "  for index, row in X_test.iterrows():\n",
        "      # Coletar as predições de todas as árvores para a observação atual\n",
        "      preds = [predict_tree(tree, row) for tree in forest]\n",
        "      # Realizar a votação majoritária para a observação atual\n",
        "      most_common_pred = Counter(preds).most_common(1)[0][0]\n",
        "      # Adicionar a predição majoritária à lista de predições finais\n",
        "      final_predictions.append(most_common_pred)\n",
        "  return final_predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jC93NuYAAp76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8PcPp7wAsu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifica_forest(forest, entrada):\n",
        "    predicoes = [classifica_arvore(arvore, entrada) for arvore in forest]\n",
        "    resultado = Counter(predicoes).most_common(1)[0][0]\n",
        "    return resultado\n",
        "\n"
      ],
      "metadata": {
        "id": "BSAFeEzHioDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifica_arvore(arvore, entrada):\n",
        "    if not isinstance(arvore, dict):  # Verifica se é um nó folha\n",
        "        return arvore\n",
        "    caracteristica = arvore['caracteristica']\n",
        "    if entrada[caracteristica] == 0:\n",
        "        return classifica_arvore(arvore['left'], entrada)\n",
        "    else:\n",
        "        return classifica_arvore(arvore['right'], entrada)\n"
      ],
      "metadata": {
        "id": "9K7GdvuSAw4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def matriz_confusao_random_forest(df, porcentagem):\n",
        "    treino = df.sample(frac=porcentagem)\n",
        "    teste = df.drop(treino.index)\n",
        "\n",
        "    confusao = [[0, 0], [0, 0]]\n",
        "\n",
        "    forest = random_forest(treino, n_trees=10, max_depth=10)\n",
        "\n",
        "    for indice, linha in teste.iterrows():\n",
        "        classificacao = classifica_forest(forest, linha.drop(alvo))\n",
        "        real = linha[alvo]\n",
        "\n",
        "        if classificacao == 1 and real == 1:\n",
        "            confusao[0][0] += 1  # Verdadeiro positivo\n",
        "        elif classificacao == 1 and real == 0:\n",
        "            confusao[0][1] += 1  # Falso positivo\n",
        "        elif classificacao == 0 and real == 1:\n",
        "            confusao[1][0] += 1  # Falso negativo\n",
        "        elif classificacao == 0 and real == 0:\n",
        "            confusao[1][1] += 1  # Verdadeiro negativo\n",
        "\n",
        "    return confusao\n",
        "\n",
        "# Calcular a matriz de confusão usando a Random Forest\n",
        "matriz_confusao_rf = matriz_confusao_random_forest(df_dummizado, 0.75)\n",
        "\n",
        "# Calcular métricas a partir da matriz de confusão\n",
        "sensitivity_rf = matriz_confusao_rf[0][0] / (matriz_confusao_rf[0][0] + matriz_confusao_rf[1][0])\n",
        "specificity_rf = matriz_confusao_rf[1][1] / (matriz_confusao_rf[0][1] + matriz_confusao_rf[1][1])\n",
        "precision_rf = matriz_confusao_rf[0][0] / (matriz_confusao_rf[0][0] + matriz_confusao_rf[0][1])\n",
        "\n",
        "print(matriz_confusao_rf)\n",
        "print(\"Sensitivity (Random Forest):\", sensitivity_rf)\n",
        "print(\"Specificity (Random Forest):\", specificity_rf)\n",
        "print(\"Precision (Random Forest):\", precision_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGOcIrTAy41",
        "outputId": "5827edc5-3410-454b-8f3a-d128abf95907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[977, 0], [0, 1054]]\n",
            "Sensitivity (Random Forest): 1.0\n",
            "Specificity (Random Forest): 1.0\n",
            "Precision (Random Forest): 1.0\n"
          ]
        }
      ]
    }
  ]
}